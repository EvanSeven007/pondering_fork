# `fiddler-tuner`: a gradient-descent tuner for the Fiddler chess engine

`fiddler-tuner` is a simple implementation of gradient descent for Fiddler. I
don't mean to brag, but it just so happens to be ðŸ”¥ blazing fast ðŸ”¥: capable of
evaluating over 60 million nodes per second on my little laptop, without even
getting into the spaghetti that is GPU programming.

## Usage

After compiling the tuner, simply run `fiddler_tuner <location of your database
file here>`. The database file must have a table titled `evaluations`, which
must have a row for each board and also have two columns: `fen` (containing the
string FEN representation of the board) and `eval` (containing the
floating-point evaluation of the position).

I personally use [this](<https://storage.googleapis.com/chesspic/datasets/2021-07-31-lichess-evaluations-37MM.db.gz>)
database file, with 37M positions.

## Approach

Fiddler's evaluation is generated by computing the weighted sum of many rules.
For instance, one rule gives a (negative) bonus for every doubled pawn a player
has. For each rule, it gets a unique weight describing its contribution to the
final evaluation. We can imagine extracting a feature vector $\boldsymbol{x}$
from any board, and then computing its static evaluation $\hat s$ by taking its
inner product with the weight vector $\boldsymbol{w}$:

$$ \hat s(\boldsymbol{x}) = \boldsymbol{w}^T \boldsymbol{x} $$

Our goal is to minimize the error between our static evaluation
$ \hat s(\boldsymbol{x}) $ and the expected evaluation $s(\boldsymbol{x})$.

However, we are generally not interested in how wrong we are in completely
winning positions: for instance, if our dataset says we should evaluate a
position as +30 pawns for White and we only evaluate it at +25, that is no
trouble. We are mostly interested in getting our evaluations right on
evaluations close to zero. We therefore generate "smoothed" evaluations $R_i$
and $\hat R_i$ by running the linear scores through a sigmoid activation
function:

$$ r(\boldsymbol{x}) = \sigma(k s(\boldsymbol{x})) $$

$$ \hat r(\boldsymbol{x}) = \sigma (k \hat s(\boldsymbol{x})) $$

$$ \sigma(x) = \frac{1}{1 - e^x} $$

In this case, $k$ is an arbitrary parameter selected to choose just how close an
evaluation must be to zero for it to have a noticeable slope in the output. We
can now formalize our problem as a minimum-squared-error argument, given $N$
total samples:

$$
\argmin_{\boldsymbol{w}} E(\boldsymbol{w}) =
\frac{1}{N} \sum_{\boldsymbol{x} \in X} \left(r(\boldsymbol{x}) - \hat r(\boldsymbol{x}) \right)^2
$$

We cannot solve this with algebra, so we settle for gradient descent. To do so,
we calculate the gradient:

$$
\nabla_{\boldsymbol{w}} E(\boldsymbol{w}) = - \frac{2 k}{N} \sum_{x \in X}
    \left(r(\boldsymbol{x}) - \hat r(\boldsymbol{x}) \right)
    \hat r(\boldsymbol{x})
    \left(1 - \hat r(\boldsymbol{x}) \right)
    \boldsymbol{x}
$$

Conveniently, this means that we can compute $\nabla_wE(w)$ in a single pass
over the dataset.

## Implementation

Because the value of most rules on a position tend to be zero, we use a sparse
representation on our feature vectors. This saves both time and space.

Because the gradient is composed of many independent computations, we
parallelize our gradient computation in each epoch. Each of $T$ threads computes
the gradient for $\frac{1}{T}$ elements of the training set, and at the end the
gradients are summed together to produce the gradient for the whole set.
