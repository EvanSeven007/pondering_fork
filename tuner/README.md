# `fiddler-tuner`: a gradient-descent tuner for the Fiddler chess engine

`fiddler-tuner` is a simple implementation of gradient descent for Fiddler.

## Usage

After compiling the tuner, simply run
`fiddler_tuner <location of your EPD file here>`.
The EPD file is a sequence of lines, each containing the FEN for a position and
the final outcome of the game.
For example, the following would be a valid EPD file:

```epd
rnb1kbnr/pp1pppp1/7p/2q5/5P2/N1P1P3/P2P2PP/R1BQKBNR w KQkq - 0 1 c9 "1/2-1/2";
8/8/1p1k4/1P6/8/3p3P/1r4P1/5K2 w - - 0 1 c9 "0-1";
8/6P1/8/1pk1r3/6RP/8/3K4/8 b - - 0 1 c9 "1-0";
```

Note that Fiddler right now uses a slightly modified version of the EPD format,
including the halfmove and fullmove clock directly, as described in
Forsyth-Edwards notation.

Fiddler was tuned with a dataset created by the method outlined in
[Zurichess](https://bitbucket.org/zurichess/zurichess/wiki/Choosing%20positions%20for%20Texel's%20Tuning%20Method).

## Approach

Fiddler's evaluation is generated by computing the weighted sum of many rules.
For instance, one rule gives a (negative) bonus for every doubled pawn a player
has.
For each rule, it gets a unique weight describing its contribution to the final
evaluation. We can imagine extracting a feature vector $\boldsymbol{x}$ from any
board, and then computing its static evaluation $\hat s$ by taking its
inner product with the weight vector $\boldsymbol{w}$:

$$ \hat s(\boldsymbol{x}) = \boldsymbol{w}^T \boldsymbol{x} $$

Our goal is to minimize the error between our static evaluation
$ \hat s(\boldsymbol{x}) $ and the expected evaluation $s(\boldsymbol{x})$.

However, we are generally not interested in how wrong we are in completely
winning positions: for instance, if our dataset says we should evaluate a
position as +30 pawns for White and we only evaluate it at +25, that is no
trouble.
We are mostly interested in getting our evaluations right on evaluations close
to zero.
We therefore generate "smoothed" evaluations $R_i$ and $\hat R_i$ by running the
linear scores through a sigmoid activation function:

$$ r(\boldsymbol{x}) = \sigma(k s(\boldsymbol{x})) $$

$$ \hat r(\boldsymbol{x}) = \sigma (k \hat s(\boldsymbol{x})) $$

$$ \sigma(x) = \frac{1}{1 - e^x} $$

Note that our dataset simply expresses positions as won, lost, or drawn, so we
actually are given $\hat r(\boldsymbol{x})$, and not $\hat s(\boldsymbol{x})$.

In this case, $k$ is an arbitrary parameter selected to choose just how close an
evaluation must be to zero for it to have a noticeable slope in the output.
We can now formalize our problem as a minimum-squared-error argument, given $N$
total samples:

$$
\argmin_{\boldsymbol{w}} E(\boldsymbol{w}) =
\frac{1}{N} \sum_{\boldsymbol{x} \in X} \left(r(\boldsymbol{x}) - \hat r(\boldsymbol{x}) \right)^2
$$

We cannot solve this with algebra, so we settle for gradient descent.
To do so, we calculate the gradient:

$$
\nabla_{\boldsymbol{w}} E(\boldsymbol{w}) = - \frac{2 k}{N} \sum_{x \in X}
    \left(r(\boldsymbol{x}) - \hat r(\boldsymbol{x}) \right)
    \hat r(\boldsymbol{x})
    \left(1 - \hat r(\boldsymbol{x}) \right)
    \boldsymbol{x}
$$

Conveniently, this means that we can compute $\nabla_w E(w)$ in a single pass
over the dataset.

## Implementation

Because the value of most rules on a position tend to be zero, we use a sparse
representation on our feature vectors.
This saves both time and space.

Because the gradient is composed of many independent computations, we
parallelize our gradient computation in each epoch.
Each of $T$ threads computes the gradient for $\frac{1}{T}$ elements of the
training set, and at the end the gradients are summed together to produce the
gradient for the whole set.
